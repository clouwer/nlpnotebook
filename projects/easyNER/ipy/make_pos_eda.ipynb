{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.extend(['../src/'])\n",
    "from config import *\n",
    "config = Config()\n",
    "\n",
    "from pyhanlp import *\n",
    "\n",
    "f = open(config.userdict, encoding = 'UTF-8')\n",
    "\n",
    "ner_pos = {}\n",
    "for line in f:\n",
    "    res = line.strip().split('\t')\n",
    "    word = res[0]\n",
    "    nature = res[1]\n",
    "    ner_pos[word] = nature\n",
    "\n",
    "f = open('../source/data/ner_data/synonym.txt', 'w+', encoding = 'UTF-8')\n",
    "CoreSynonymDictionary = JClass(\"com.hankcs.hanlp.dictionary.CoreSynonymDictionary\")\n",
    "word_array = [i for i in ner_pos.keys()]\n",
    "similarity = {}\n",
    "for a in word_array:\n",
    "    similarity[a] = []\n",
    "    for b in word_array[word_array.index(a)+ 1:]:\n",
    "        if CoreSynonymDictionary.similarity(a, b) == 1.0:\n",
    "            f.write(a + '\\t' + b + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhanlp import *\n",
    "\n",
    "f = open(config.userdict, encoding = 'UTF-8')\n",
    "\n",
    "ner_pos = {}\n",
    "for line in f:\n",
    "    res = line.strip().split('\t')\n",
    "    word = res[0]\n",
    "    nature = res[1]\n",
    "    ner_pos[word] = nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.label_dict = {'检查和检验': 'CHECK',\n",
    "              '症状和体征': 'SIGNS',\n",
    "              '疾病和诊断': 'DISEASE',\n",
    "              '治疗': 'TREATMENT',\n",
    "              '身体部位': 'BODY'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "f = open('../source/data/ner_data/ner_train.txt', 'w+',encoding = 'UTF-8')\n",
    "for root,dirs,files in os.walk(config.origin_datapath):\n",
    "    for file in files:\n",
    "        filepath = os.path.join(root, file)    \n",
    "        res_dict = {}\n",
    "        text = re.sub('\\n', '', open(filepath, encoding = 'UTF-8').read())\n",
    "        sg_word = sorted([word for word in ner_pos.keys() if word in text],key = lambda i:len(i),reverse=False)\n",
    "        sg_words = []\n",
    "        for word in sg_word:\n",
    "            sg_words = sg_words + [word] * text.count(word)\n",
    "        sg_nature = [ner_pos[word] for word in sg_words]\n",
    "        words_begin = []; words_end = []\n",
    "        for word in sg_word:\n",
    "            if word in ['胸部正位+左斜位片','A+B']:\n",
    "                word = word[:word.index('+')] + '\\\\'+ word[word.index('+'):]\n",
    "            words_begin = words_begin + [m.start() for m in re.finditer(word, text)]\n",
    "            words_end = words_end + [m.end()-1 for m in re.finditer(word, text)]\n",
    "        res_dict = {}\n",
    "        for w in range(len(sg_words)):\n",
    "            res = sg_words[w]\n",
    "            start = words_begin[w]\n",
    "            end = words_end[w]\n",
    "            label = config.label_dict[sg_nature[w]]\n",
    "            for i in range(start, end+1):\n",
    "                if i == start:\n",
    "                    label_cate = 'B-' + label\n",
    "                else:\n",
    "                    label_cate = 'I-' + label\n",
    "                res_dict[i] = label_cate\n",
    "        for indx, char in enumerate(text):\n",
    "            char_label = res_dict.get(indx, 'O')\n",
    "            f.write(char + '\\t' + char_label + '\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
